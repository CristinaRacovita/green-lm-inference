
# load embedding model, language model, vector db

# get queries

# for each query: embed it, get from the vector db top k answers, create the prompt, generate answer

# before benchmarking answer to one question